Data preparation in progress for the kiba dataset...
[[11.1                nan         nan ...         nan         nan
          nan]
 [11.1                nan         nan ...         nan         nan
          nan]
 [12.1        11.99999842         nan ...         nan 14.40016227
  11.30000024]
 ...
 [        nan         nan         nan ...         nan         nan
  12.637602  ]
 [        nan         nan         nan ...         nan         nan
          nan]
 [        nan         nan         nan ...         nan         nan
          nan]]
/data/home/congn/MyCode/Experiment/MSGC-DTA/utils.py:90: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:641.)
  return torch.sparse.FloatTensor(indices, values, shape)
/data/conda/congn/envs/MSGC-DTA/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/data/home/congn/MyCode/Experiment/MSGC-DTA/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
  GCNData = DATA.Data(x=torch.Tensor(features), edge_index=torch.LongTensor(edge_index).transpose(1, 0))
(2111, 100)
(2111, 300)
(2111, 512)
(228, 100)
(228, 768)
(228, 1280)
Model preparation...
Start training...
Training on 98400 samples...
Total number of parameters: 4396164
Trainable parameters: 4396164
/data/conda/congn/envs/MSGC-DTA/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Train epoch: 1 [0/98400 (0%)]	Loss: 145.822220
Train epoch: 1 [5120/98400 (5%)]	Loss: 73.047287
Train epoch: 1 [10240/98400 (10%)]	Loss: 16.365028
Train epoch: 1 [15360/98400 (16%)]	Loss: 14.446831
Train epoch: 1 [20480/98400 (21%)]	Loss: 11.040077
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    train_predict()  # Training data
  File "main.py", line 145, in train_predict
    train(model, predictor, device, train_loader, drug_graphs_DataLoader, target_graphs_DataLoader, args.lr, epoch+1,
  File "main.py", line 52, in train
    epoch_loss += loss.item()
KeyboardInterrupt
